#!/usr/bin/env python3
"""
Generate README.md from `library.bib`, grouped by tags (BibTeX `keywords`)
and (new) grouped/indexed by Zotero collections.

- Keeps README header until marker: <!-- AUTOGENERATED: DO NOT EDIT BELOW THIS LINE -->
- TeX cleanup for labels (e.g., {\textbar} -> |)
- Groups by Tags and by Collections; shows collection chips on entries
- Supports comma/semicolon separated keywords and collection paths

Requires: pip install bibtexparser
"""

import re
import sys
from pathlib import Path

def normalize_entry(entry: dict) -> dict:
    """Normalize BibTeX entry fields for consistency."""
    e = {k.lower(): v for k, v in entry.items()}
    # Trim whitespace
    for k in list(e):
        if isinstance(e[k], str):
            e[k] = e[k].strip()

    # Map date → year if year missing
    if not e.get("year") and e.get("date"):
        import re
        m = re.search(r"\d{4}", e["date"])
        if m:
            e["year"] = m.group(0)

    # Normalize journal/booktitle → container
    e["container"] = e.get("journal") or e.get("booktitle") or e.get("publisher", "")

    return e

try:
    import bibtexparser
except ImportError:
    sys.stderr.write("Missing dependency: bibtexparser. Install with `pip install bibtexparser`\n")
    sys.exit(1)

ROOT = Path(__file__).resolve().parents[1]
BIB_PATH = ROOT / "library.bib"
README_PATH = ROOT / "README.md"
MARKER = "<!-- AUTOGENERATED: DO NOT EDIT BELOW THIS LINE -->"


# ----------------------- helpers -----------------------
def clean_tex(s: str) -> str:
    """Minimal LaTeX -> plain text normalisation for labels/headings."""
    if not s:
        return ""
    s = s.replace(r"{\textbar}", "|").replace(r"\textbar", "|")
    s = s.replace(r"\&", "&")
    s = re.sub(r"[{}]", "", s)          # drop stray braces
    s = re.sub(r"\s+", " ", s).strip()
    return s

def norm_keywords(value: str):
    """Return list[(group_key, display_label)] from keywords."""
    if not value:
        return []
    raw = re.split(r"[;,]", value)
    cleaned = [clean_tex(w.strip()) for w in raw if w.strip()]
    return [(w.lower(), w) for w in cleaned]

def norm_list(value: str):
    """Split semi/comma/newline-separated list; trim; clean TeX."""
    if not value:
        return []
    raw = re.split(r"[;,\n]", value)
    return [clean_tex(w.strip()) for w in raw if w.strip()]

def citekey_anchor(key: str) -> str:
    return f"<a id='{key}'></a>"

def format_authors(persons: str) -> str:
    if not persons:
        return ""
    parts = [p.strip() for p in re.split(r"\s+and\s+", persons)]
    if len(parts) == 1:
        return parts[0]
    if len(parts) == 2:
        return f"{parts[0]} & {parts[1]}"
    return f"{parts[0]} et al."

def entry_sort_key(e):
    author = (e.get("author") or "").lower()
    year = e.get("year") or "9999"
    title = (e.get("title") or "").lower()
    return (author, year, title)

def entry_to_md(e):
    key = e.get("ID", "")
    typ = (e.get("ENTRYTYPE") or "").capitalize()
    title = (e.get("title") or "").strip(" {}")
    authors = format_authors(e.get("author") or "")
    year = e.get("year") or ""
    venue = e.get("journal") or e.get("booktitle") or e.get("publisher") or ""
    doi = (e.get("doi") or "").strip()
    url = (e.get("url") or "").strip()
    colls = norm_list(e.get("collections") or e.get("groups") or "")

    bits = []
    if title:
        bits.append(f"**{title}**")
    meta = []
    if authors: meta.append(authors)
    if year:    meta.append(str(year))
    if venue:   meta.append(venue)
    if typ:     meta.append(typ)
    if meta:
        bits.append(" — " + ", ".join(meta))

    tail = []
    if doi:
        tail.append(f"DOI: [{doi}](https://doi.org/{doi})")
    if url:
        tail.append(f"[Link]({url})")

    md = f"- {citekey_anchor(key)}" + " ".join(bits)
    if tail:
        md += " · " + " · ".join(tail)
    if colls:
        md += "  \n  " + " ".join(f"`{c}`" for c in colls)  # collection chips on new line
    return md
# -------------------------------------------------------


def main():
    if not BIB_PATH.exists():
        sys.stderr.write(f"Missing {BIB_PATH}. Export your library to BibTeX as 'library.bib'.\n")
        sys.exit(1)

    with open(BIB_PATH, "r", encoding="utf-8") as f:
        db = bibtexparser.load(f)

    # -------- collections (Zotero/BBT "Include collections") ----------
    coll_groups = {}  # key -> {"label": path, "entries":[...] }
    for e in db.entries:
        for path in norm_list(e.get("collections") or e.get("groups") or ""):
            k = path.lower()
            coll_groups.setdefault(k, {"label": path, "entries": []})
            coll_groups[k]["entries"].append(e)
    ordered_colls = sorted(coll_groups.values(), key=lambda g: g["label"].lower())

    # -------------------- tags --------------------
    tag_groups = {}
    untagged = []
    for e in db.entries:
        kws = norm_keywords(e.get("keywords","") or e.get("keyword",""))
        if not kws:
            untagged.append(e)
        else:
            for gkey, label in kws:
                tag_groups.setdefault(gkey, {"label": label, "entries": []})
                tag_groups[gkey]["entries"].append(e)
    ordered_tags = sorted(tag_groups.values(), key=lambda g: g["label"].lower())

    # -------------------- build README --------------------
    body = []

    # Collections index + sections
    body.append("## Collections index\n")
    if ordered_colls:
        idx = " · ".join(
            f"[{g['label']}](#{g['label'].lower().replace(' ', '-').replace('>', '')})"
            for g in ordered_colls
        )
        body.append(idx + "\n")
        for g in ordered_colls:
            body.append(f"\n### {g['label']}\n")
            for e in sorted(g["entries"], key=entry_sort_key):
                body.append(entry_to_md(e))

    # Tag index + sections
    body.append("\n## Tag index\n")
    if ordered_tags:
        idx = " · ".join(
            f"[{g['label']}](#{g['label'].lower().replace(' ', '-')})"
            for g in ordered_tags
        )
        body.append(idx + "\n")
        for g in ordered_tags:
            body.append(f"\n### {g['label']}\n")
            for e in sorted(g["entries"], key=entry_sort_key):
                body.append(entry_to_md(e))

    # Untagged
    if untagged:
        body.append("\n### (Untagged)\n")
        for e in sorted(untagged, key=entry_sort_key):
            body.append(entry_to_md(e))

    generated = "\n".join(body).rstrip() + "\n"

    # Merge into README with marker
    if README_PATH.exists():
        original = README_PATH.read_text(encoding="utf-8")
        if MARKER in original:
            head = original.split(MARKER, 1)[0].rstrip()
            final = head + "\n\n" + MARKER + "\n\n" + generated
        else:
            final = original.rstrip() + "\n\n" + MARKER + "\n\n" + generated
    else:
        final = f"# Reference Library\n\n---\n\n{MARKER}\n\n{generated}"

    README_PATH.write_text(final, encoding="utf-8")
    print(f"Wrote grouped list to {README_PATH}")


if __name__ == "__main__":
    main()